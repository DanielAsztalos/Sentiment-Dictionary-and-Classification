{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Sentiment Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data used to build a sentiment dictionary:\n",
    "\n",
    "- 200000 samples from Amazon product data (Movies and TV category): http://jmcauley.ucsd.edu/data/amazon/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/daniel/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/daniel/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/daniel/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/daniel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "import json\n",
    "from joblib.parallel import Parallel, delayed\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "# download additional data for the nltk functions used\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_data = dict()\n",
    "text_data = \"\"\n",
    "\n",
    "# get the text of the first 200_000 reviews using all available cpus\n",
    "\n",
    "with open(\"Movies_and_TV_5.json\", \"rt\") as inf:\n",
    "    text_data = \\\n",
    "        Parallel(n_jobs=multiprocessing.cpu_count())(delayed(\\\n",
    "            lambda x: (json.loads(x))['reviewText'])(line)\\\n",
    "            for line in inf.readlines()[:200000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that removes special characters from a text\n",
    "# converts it to lowercase and tokenizes it\n",
    "def tokenize(line):\n",
    "    spec_chars = \".,?/!\\'\\\"()[]{};:<>|_-=+“”\"\n",
    "    line.replace(\"&#34;\", \"\")\n",
    "    train_data = []\n",
    "    \n",
    "    for sentence in sent_tokenize(line):\n",
    "        words = [word.strip().lower() \\\n",
    "                     for word in word_tokenize(sentence)\\\n",
    "                         if not (len(word) == 1 and word in spec_chars)]\n",
    "        train_data.append(words)\n",
    "        \n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize every review\n",
    "train_data = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(tokenize)(line) for line in text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the resulting lists into one list\n",
    "x = []\n",
    "for l in train_data:\n",
    "    x += l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a word2vec model on the amazon reviews\n",
    "model = Word2Vec(x, min_count=1, size=100, window=5, workers=multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a few positive and negative words\n",
    "positive = [\"well\", \"good\", \"better\", \"best\", \"happy\", \"awesome\", \n",
    "            \"amazing\", \"great\", \"nice\", \"fantastic\",\"funny\", \"happy\",\n",
    "            'creatively', 'intelligently','laughable']\n",
    "negative = [\"bad\", \"worse\", \"worst\", \"horrible\", \"poor\", \"poorly\", \n",
    "            \"weak\", 'disappointed', \"weakest\", \"unfunny\"]\n",
    "\n",
    "# define the accepted POS tags\n",
    "accepted = ['JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert these lists to sets\n",
    "positive = set(positive)\n",
    "negative = set(negative)\n",
    "temp_list = []\n",
    "\n",
    "for _ in range(4):\n",
    "    \n",
    "    # find words that are similar to the defined ones\n",
    "    # according to the word2vec model trained previously\n",
    "    for w in positive:\n",
    "        res = model.wv.most_similar(w, topn=10)\n",
    "        res = [x[0] for x in res if not x[0] in negative and nltk.pos_tag([x[0]])[0][1] in accepted]\n",
    "        temp_list += res\n",
    "    \n",
    "    # add these to the positive words set\n",
    "    for x in temp_list:\n",
    "        positive.add(x)\n",
    "    \n",
    "    temp_list = []\n",
    "    \n",
    "    # repeat this process with the negative words too\n",
    "    for w in negative:\n",
    "        res = model.wv.most_similar(w, topn=10)\n",
    "        res = [x[0] for x in res if not x[0] in positive and nltk.pos_tag([x[0]])[0][1] in accepted]\n",
    "        temp_list += res\n",
    "    \n",
    "    for x in temp_list:\n",
    "        negative.add(x)\n",
    "    temp_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'artistically\",\n",
       " '1915-92',\n",
       " '1924-',\n",
       " 'able',\n",
       " 'accurately',\n",
       " 'adequately',\n",
       " 'admirable',\n",
       " 'adorable',\n",
       " 'adventurous',\n",
       " 'amateurish',\n",
       " 'amazing',\n",
       " 'ambiguous',\n",
       " 'anachronistic',\n",
       " 'anxious',\n",
       " 'appreciative',\n",
       " 'artfully',\n",
       " 'artistically',\n",
       " 'atmospheric',\n",
       " 'atypical',\n",
       " 'aural',\n",
       " 'authentic',\n",
       " 'authentically',\n",
       " 'awesome',\n",
       " 'beatifully',\n",
       " 'beautfully',\n",
       " 'beautifully',\n",
       " 'believable',\n",
       " 'believably',\n",
       " 'best',\n",
       " 'best-known',\n",
       " 'best-loved',\n",
       " 'better',\n",
       " 'bigger',\n",
       " 'bitingly',\n",
       " 'bizarrely',\n",
       " 'breathtakingly',\n",
       " 'brilliantly',\n",
       " 'broadly',\n",
       " 'buitifully',\n",
       " 'capably',\n",
       " 'carefully',\n",
       " 'cautious',\n",
       " 'charismatic',\n",
       " 'charmingly',\n",
       " 'choppy',\n",
       " 'cleverly',\n",
       " 'cliche-ish',\n",
       " 'clumsily',\n",
       " 'colorfully',\n",
       " 'comedatic',\n",
       " 'comical',\n",
       " 'commendable',\n",
       " 'compellingly',\n",
       " 'convincingly',\n",
       " 'craftily',\n",
       " 'creatively',\n",
       " 'credible',\n",
       " 'credibly',\n",
       " 'creditable',\n",
       " 'dazzlingly',\n",
       " 'deftly',\n",
       " 'delicately',\n",
       " 'deliciously',\n",
       " 'delighted',\n",
       " 'delightfully',\n",
       " 'devilishly',\n",
       " 'digitally',\n",
       " 'dynamically',\n",
       " 'earliest',\n",
       " 'eclectic',\n",
       " 'effectively',\n",
       " 'elaborately',\n",
       " 'elegantly',\n",
       " 'eloquently',\n",
       " 'energetic',\n",
       " 'evil-comical',\n",
       " 'exaggerated',\n",
       " 'excellently',\n",
       " 'exceptional',\n",
       " 'excitingly',\n",
       " 'exemplary',\n",
       " 'expensively',\n",
       " 'expertly',\n",
       " 'exploitative',\n",
       " 'exploitive',\n",
       " 'exquisitely',\n",
       " 'extraordinary',\n",
       " 'fabulous',\n",
       " 'fabulously',\n",
       " 'faithfully',\n",
       " 'fantastic',\n",
       " 'fantastically',\n",
       " 'farcical',\n",
       " 'father-defendant',\n",
       " 'film.exquisitely',\n",
       " 'finely',\n",
       " 'finest',\n",
       " 'flawlessly',\n",
       " 'funny',\n",
       " 'gloriously',\n",
       " 'good',\n",
       " 'good-hearted',\n",
       " 'gorgeously',\n",
       " 'great',\n",
       " 'greater',\n",
       " 'greatest',\n",
       " 'halarious',\n",
       " 'happy',\n",
       " 'hastily',\n",
       " 'hauntingly',\n",
       " 'higher',\n",
       " 'hilarious',\n",
       " 'hilariously',\n",
       " 'hillarious',\n",
       " 'homoerotic',\n",
       " 'humorous',\n",
       " 'humourous',\n",
       " 'hysterical',\n",
       " 'hysterically',\n",
       " 'idiotic',\n",
       " 'ii.expertly',\n",
       " 'illogical',\n",
       " 'imaginative',\n",
       " 'imaginatively',\n",
       " 'impeccable',\n",
       " 'impeccably',\n",
       " 'impressively',\n",
       " 'incisive',\n",
       " 'inclined',\n",
       " 'incredible',\n",
       " 'ineptly',\n",
       " 'infectious',\n",
       " 'ingenious',\n",
       " 'ingeniously',\n",
       " 'innovative',\n",
       " 'inquisitive',\n",
       " 'insanely',\n",
       " 'intelligently',\n",
       " 'intricately',\n",
       " 'introspective',\n",
       " 'inventive',\n",
       " 'inventively',\n",
       " 'irresistable',\n",
       " 'irresistible',\n",
       " 'kittenishly',\n",
       " 'larger',\n",
       " 'laugh-out-loud',\n",
       " 'laughable',\n",
       " 'lavishly',\n",
       " 'lazily',\n",
       " 'less',\n",
       " 'lesser-known',\n",
       " 'likable',\n",
       " 'likeable',\n",
       " 'lovable',\n",
       " 'loveable',\n",
       " 'lovingly',\n",
       " 'low-key',\n",
       " 'lower',\n",
       " 'ludicrous',\n",
       " 'lushly',\n",
       " 'magnificently',\n",
       " 'mandel-commentary',\n",
       " 'marvellous',\n",
       " 'marvellously',\n",
       " 'marvelous',\n",
       " 'marvelously',\n",
       " 'masterfully',\n",
       " 'melodramatic',\n",
       " 'memorable',\n",
       " 'meticulously',\n",
       " 'mischievous',\n",
       " 'more',\n",
       " 'movingly',\n",
       " 'naturalistic',\n",
       " 'negatively',\n",
       " 'neurotic',\n",
       " 'nice',\n",
       " 'nicely',\n",
       " 'nonsensical',\n",
       " 'not-so-obvious',\n",
       " 'nuanced',\n",
       " 'open-minded',\n",
       " 'oscar-worthy',\n",
       " 'outlandish',\n",
       " 'outrageous',\n",
       " 'outrageously',\n",
       " 'outstanding',\n",
       " 'outstandingly',\n",
       " 'over-the-top',\n",
       " 'painstakingly',\n",
       " 'passable',\n",
       " 'perceptively',\n",
       " 'perfectly',\n",
       " 'perfectly-timed',\n",
       " 'phenomenally',\n",
       " 'pleased',\n",
       " 'poetically',\n",
       " 'poignantly',\n",
       " 'powerfully',\n",
       " 'prepared',\n",
       " 'preposterous',\n",
       " 'professionally',\n",
       " 'psychologically',\n",
       " 'quotable',\n",
       " 'rather',\n",
       " 'raucous',\n",
       " 'ravishingly',\n",
       " 'ready',\n",
       " 'realistic',\n",
       " 'realistically',\n",
       " 'remarkable',\n",
       " 'repeatable',\n",
       " 'ridiculous',\n",
       " 'riotous',\n",
       " 'riotously',\n",
       " 'satisfied',\n",
       " 'scary',\n",
       " 'seductively',\n",
       " 'self-centered',\n",
       " 'self-conscious',\n",
       " 'sensational',\n",
       " 'sensitively',\n",
       " 'serviceable',\n",
       " 'sharply',\n",
       " 'silly',\n",
       " 'sincere',\n",
       " 'situational',\n",
       " 'skillfully',\n",
       " 'sluggish',\n",
       " 'smaller',\n",
       " 'smartly',\n",
       " 'snappy',\n",
       " 'solid',\n",
       " 'spectacularly',\n",
       " 'spilbergian',\n",
       " 'splendidly',\n",
       " 'strikingly',\n",
       " 'stronger',\n",
       " 'strongest',\n",
       " 'stunningly',\n",
       " 'stupendous',\n",
       " 'stylishly',\n",
       " 'subtly',\n",
       " 'suitably',\n",
       " 'sumptuously',\n",
       " 'superbly',\n",
       " 'superlatively',\n",
       " 'suspensefully',\n",
       " 'sweetly',\n",
       " 'sympathetically',\n",
       " 'tastefully',\n",
       " 'tautly',\n",
       " 'terrifically',\n",
       " 'then-blacklisted',\n",
       " 'thoughtfully',\n",
       " 'tightly',\n",
       " 'tolerable',\n",
       " 'unable',\n",
       " 'unbearably',\n",
       " 'unbelievable',\n",
       " 'uncanny',\n",
       " 'unconventional',\n",
       " 'undeniable',\n",
       " 'underplayed',\n",
       " 'understated',\n",
       " 'uneven',\n",
       " 'unforgetable',\n",
       " 'unforgettable',\n",
       " 'uninspired',\n",
       " 'unintentional',\n",
       " 'unintentionally',\n",
       " 'unlikable',\n",
       " 'unmistakable',\n",
       " 'unnatural',\n",
       " 'unpredictable',\n",
       " 'unrealistic',\n",
       " 'unsentimental',\n",
       " 'unusual',\n",
       " 'unwilling',\n",
       " 'uproarious',\n",
       " 'uproariously',\n",
       " 'visually',\n",
       " 'vividly',\n",
       " 'well',\n",
       " 'well-directed',\n",
       " 'well-filmed',\n",
       " 'well-photographed',\n",
       " 'well-scripted',\n",
       " 'wickedly',\n",
       " 'willing',\n",
       " 'wonderfully',\n",
       " 'wondrously'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the positive word set\n",
    "positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the positive and negative words into a dictionary and \n",
    "# give them sentiment scores\n",
    "dictionary = dict()\n",
    "for word in positive:\n",
    "    dictionary[word] = 1\n",
    "    \n",
    "for word in negative:\n",
    "    dictionary[word] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dictionary to a json file\n",
    "with open(\"dict.json\", \"wt\") as outf:\n",
    "    json.dump(dictionary, outf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset used for classification:\n",
    "\n",
    "- IMDB 50K dataset: https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary modules\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data into a dataframe\n",
    "imdb_data = pd.read_csv('IMDB Dataset.csv')\n",
    "imdb_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all \"<br />\" tags from the reviews\n",
    "for idx, row in imdb_data.iterrows():\n",
    "    txt = row.review.replace(\"<br />\", \" \")\n",
    "    imdb_data.iloc[idx, 0] = txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and validation sets\n",
    "X, y = imdb_data['review'], imdb_data['sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a pipeline for the multinomial naive-bayes model\n",
    "clf_model = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('model', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert labels to integers\n",
    "y_train[y_train == \"negative\"] = -1\n",
    "y_train[y_train == \"positive\"] = 1\n",
    "y_test[y_test == \"negative\"] = -1\n",
    "y_test[y_test == \"positive\"] = 1\n",
    "\n",
    "y_train = y_train.astype('int').ravel()\n",
    "y_test = y_test.astype('int').ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.66084404,  0.77903229,  0.62037838, ..., -0.61963381,\n",
       "       -0.65926726, -0.80904578])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and predict using MultinomialNB\n",
    "clf_model.fit(X_train, y=y_train.ravel())\n",
    "pred = clf_model.predict_proba(X_test)\n",
    "predicted_bayes = np.array([-row[0] if np.max(row) == row[0] else row[1] for row in pred])\n",
    "predicted_bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_pred = clf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8611333333333333\n",
      "Precision:  0.8859736207630123\n",
      "Recall:  0.8300558065373372\n",
      "F1 score:  0.8571036564450848\n"
     ]
    }
   ],
   "source": [
    "# print evaluation metrics\n",
    "\n",
    "def metrics(y_test, y_pred):\n",
    "    print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "    print(\"Precision: \", precision_score(y_test, y_pred))\n",
    "    print(\"Recall: \", recall_score(y_test, y_pred))\n",
    "    print(\"F1 score: \", f1_score(y_test, y_pred))\n",
    "    \n",
    "metrics(y_test, discrete_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sentiment dictionary\n",
    "with open(\"dict.json\", \"rt\") as inf:\n",
    "    sent_dictionary = json.load(inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that calculates sentiment scores for \n",
    "# each review using the sentiment dictionary\n",
    "def analyse_dict(data):\n",
    "    sentiments = []\n",
    "\n",
    "    for idx, txt in data.items():\n",
    "        # init sentiment for review\n",
    "        sent = 0\n",
    "        # iterate through sentences of review\n",
    "        for sentence in sent_tokenize(txt):\n",
    "            negative = 0\n",
    "            # iterate through words of the sentence\n",
    "            for word in word_tokenize(sentence):\n",
    "                # process word\n",
    "                w = word.lower().strip()\n",
    "                # if word is in the list than change the polarity of \n",
    "                # the sentiment for the next 5 words\n",
    "                if w in ['not', 'wasn\\'t', 'isn\\'t', 'weren\\'t']:\n",
    "                    negative = 5\n",
    "                elif w in sent_dictionary.keys():\n",
    "                    # else if word is in the dictionary\n",
    "                    # then add sentiment score to the cumulative\n",
    "                    # score\n",
    "                    if negative != 0:\n",
    "                        sent += -sent_dictionary[w]\n",
    "                        negative -= 1\n",
    "                    else:\n",
    "                        sent += sent_dictionary[w]\n",
    "        # append cumulative score of review to the list of sentiment scores\n",
    "        sentiments.append(sent)\n",
    "    \n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentiment scores for the train data\n",
    "dictionary_train = analyse_dict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that finds the threshold value below which a \n",
    "# sentiment score is considered to be a negative sentiment\n",
    "def find_threshold(X, y):\n",
    "    # list of possible threshold values\n",
    "    threshold = [i for i in range(10)]\n",
    "    results = []\n",
    "\n",
    "    # find threshold value that maximizes the accuracy score of \n",
    "    # the predictions based on the sentiment dictionary\n",
    "    for t in threshold:\n",
    "        pred = [-1 if x < t else 1 for x in X]\n",
    "        pred = np.array(pred)\n",
    "        results.append(accuracy_score(y, pred))\n",
    "    m = max(results)\n",
    "    return results.index(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = find_threshold(dictionary_train, y_train)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for the test dataset\n",
    "dictionary_test = analyse_dict(X_test)\n",
    "dictionary_predict = [-1 if x < threshold else 1 for x in dictionary_test]\n",
    "dictionary_predict = np.array(dictionary_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine predictions of the two methods presented above\n",
    "predict_combined = 0.6 * predicted_bayes + 0.4 * dictionary_predict\n",
    "predict_combined = np.array([1 if x >= 0 else -1 for x in predict_combined])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8270666666666666\n",
      "Precision:  0.82109375\n",
      "Recall:  0.8378952963061387\n",
      "F1 score:  0.8294094436406682\n"
     ]
    }
   ],
   "source": [
    "metrics(y_test, predict_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6484\n",
      "Precision:  0.6241181657848325\n",
      "Recall:  0.7523252723890513\n",
      "F1 score:  0.6822508735992289\n"
     ]
    }
   ],
   "source": [
    "predict_combined = 0.2 * predicted_bayes + 0.8 * dictionary_predict\n",
    "predict_combined = np.array([1 if x >= 0 else -1 for x in predict_combined])\n",
    "metrics(y_test, predict_combined)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
